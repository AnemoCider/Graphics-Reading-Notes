# Nanite: virtulized geometry

参考Epic的分享[^1]。

## Intro

Virtual texturing让美术可以用巨大的texture，不用关心内存开销。与之类似的是，virtualized geometry理论上可以让美术随意使用电影级的资产，不用考虑poly count, draw call次数，或者内存，并且不会有质量损失。

然而，texture更多是内存方面的限制，但是geometry会涉及到管线的更多部分，非常影响渲染开销；另外，geometry不像texture一样可以比较轻易地filter。

### Options

#### Voxels

用Voxel作为场景的高精度表示并不算很新的想法。早在2008年卡神[^2]就提出过用sparse voxel octree(SVO)来加速ray tracing的想法，其一是ray trace三角形的开销不低，另一方面是他认为未来需要texel级别精度的geometry，而光栅化管线并不擅长渲染比像素小的三角形（了解过nanite的朋友大概会觉得这很熟悉...但这已经是16年前的观点了）(疑问：这是否也属于software raster要解决的问题之一？)。另外，目前常用的表达高精度模型的方式是粗糙的triangle mesh + 高精度的color和displacement map，然后用virtual texturing来支持；而使用voxel可以直接把per-sample的高精度数据存下来，数据结构层面要简洁很多。[^3]

Unreal尝试使用的是sdf voxel。然而，即使是在优化之后，voxel的表示仍然需要6倍的数据量，并且最终mesh转voxel的uniform resampling也会带来相当的质量损失。另外，voxel的表达与传统的美术资产，比如uv mapping的兼容并不好，所以这套流程需要改的东西太多了。除此之外，sdf也有很多传统问题。总体评价是未来可期。

#### Subdivision surfaces

尽管Subdivision上限非常高，但是并不能做到简化模型；而现实是游戏里一定需要大量使用LOD这样减少顶点数的手段。所以这不能作为普遍方案来用。

#### Displacement Maps

Displacement map可以有效地减少顶点数。然而，displacement有固有的几何表达能力的缺陷，比如不能把一个球displace成环面，因此难以表达特定模型。另外，normal/displacement map也需要转Voxel那样的uniform resampling，对于hard surface很容易造成质量损失。所以这也很难作为普遍方案。

#### Points

Point-based的问题是缺少connectivity信息（没有index buffer的triangle mesh），所以得去填点之间的gap。现代ml denoising可以解决一部分这个问题，但不能解决全部。

#### Triangles

上述的做法在特定情境下或许各有优势，但unreal engine必须要一个通用的方案。所以最终我们又回到了triangle mesh.

## GPU Driven Pipeline

### Building Blocks

Nanite的开发基础是Unreal的retained mode渲染，也就是会有一个GPU端的scene。另外，mesh相关的数据（vertex和index buffer）都放在一个resource里，所以就可以只用一发dispatch做culling，或者一次DrawIndirect做depth pass.

### Background: GPU Driven

基于刺客信条（下称AC）的这篇经典的分享[^4]。

#### Draw Call, Draw Indirect, and Bindless

参考这篇[^5]。由于draw call有overhead（主要是切换state和resource），渲染的瓶颈有时是在CPU上。早期的解法包括：

- OpenGL 3的instancing。然而，instancing限制了模型的复杂度。
- Batching。对静态物体很好用，但是batching会导致剔除的粒度变大、效果变差；同时，batching会有内存开销，比如Unity的static batching会复制每个gameObject的mesh，即使它们用的是同一个model。

一种比较灵活的解法是合并resources， 例如VAO直接打包起来用base vertex去offset, texture用texture array。这样避免了资源切换的大部分开销，但是：

- draw call submission本身的开销仍无法避免，例如driver的状态检查。
- Culling，CPU渲染occluder会有不小的开销，而从GPU回读depth又会有延迟。

因此，更好的解法应当是让GPU自己去做排序、剔除等前置工作，并且直接提交draw call。

Draw Indirect: 首先需要把模型的vertex和index各自合并到一个大buffer里，然后在各自的draw call command里设置offset，接着把command写到一个buffer object里，最后通过一发multi draw indirect来提交。这样既实现了vertex/index buffer的bindless、消除了切换resource的开销，又避免了多次draw call的overhead。

Draw indirect也并非完全没有限制。例如，涉及到不同vertex format的时候，需要每种format issue一次indirect draw call。解决这个问题的思路是，把vertex attributes通过buffer传给vertex shader，在vertex shader里用`gl_VertexID`以及`gl_VertexID`去取，而不是把attributes直接通过vertex buffer传递。

其他的bindless[^6]:

- texture: texture array。更严谨地说[^7]，比较先进的做法是类似Vulkan的descriptor indexing，不需要静态指定size、array里面的每个元素不需要使用相同的的格式。

- Material: Ubershader。静态的shader permutation，像unreal，在底层应该还是需要分别bind的；动态branching有可能实现真正的bindless，但是shader本身运行的效率应该会下降很多。

把vertex/index打包的一个问题是如何增加或删除其中的mesh数据。一种解决办法是通过拷贝buffer的数据来覆盖被删除的部分，例如通过`vkCmdCopyBuffer`的`VkBufferCopy`参数指定region。

#### AC: Mesh Cluster

AC最开始的方案是DrawInstancedIndirect，也就是把模型拆分成64个vertex strip为一组的cluster。对于顶点数不是64整数倍的mesh，需要插入degenerate triangle作为padding。然而，degenerate triangle会导致内存的浪费，而以cluster为单位的instancing会导致不确定的cluster order，进而产生z-fighting。

AC采取的解决办法是MultiDrawIndexedInstancedIndirect。这样做的好处之一是每个sub-drawcall有单独的`IndexCountPerInstance`，所以我们不再需要统一的64个vertex strip了。具体来说，每个mesh instance (mesh + transform)对应一个sub-drawcall；对应的index buffer会实时构建。

#### Vertex Fetch

##### Merge-instancing

比较早的vertex fetch思路来自merge-instancing[^8]。这适用于需要batch多个mesh，每个有多份instance的情况。一种做法是每个mesh来一发drawInstanced，代价就是drawcall增多；另一种是把每个mesh的每个instance的vertex/index数据都复制一遍，合并到一个大的buffer里，代价就是浪费很多内存。merge-instancing的思路是，首先merge每个mesh（而不是每个instance）的vertex/index数据到shared buffer，然后用一个drawcall提交总的顶点数量，最后在vertex shader里面根据vertexId求出实际的index和instanceId，去fetch真正的vertex和instance数据。

**这里贴代码截图**

为了求出index和instanceId，需要固定每个instance的顶点数（也就是freq），也就是要拆mesh。不足freq的部分需要padding，所以freq不能太大。在这种情况下，较大的mesh就会被拆成多份，从而导致需要复制instance data。

AC指出，这种做法本质上是在vertex shader里模拟index buffer，由此产生的一个问题是无法利用post transform vertex cache。在单次drawcall中，vertex shader会缓存输出，用的key是vertexId + instanceId。而在merge-instancing中，vertexId则完全不会重复。

MultiDrawIndirect看似优于这种做法，但实际上它会给command processor带来更大的压力，以及，GPU实际上并不能把不同的sub-drawcall打包到同一个warp里。也就是说，对于顶点数比较低的mesh，MDI可能会更慢[^9]。

##### Reducing vertex info memory cost

通过vertex fetch可以做到一些有意思的hack。例如，对于处于同一位置但是uv或者normal不同的两个vertex，在正常情况下，我们需要把它们当成两个完全不同的vertex，也就是需要多存一份重复的position。然而，在vertex fetch的支持下，我们可以只存一个position，然后把position的index和uv/normal的index编码成vertex的index，在vertex fetch的时候解码vertexId，分别去拿信息。[^10]

##### Vertex Fetch Performance

AC的benchmark显示，对于AMD GCN，这种fetch from buffer做法的性能甚至超过硬件的fetch，原因是GPU的coalesce以及latency hiding。实际上，GCN硬件fetch的底层就是从buffer fetch的。部分iOS硬件，例如A11，也是一样的[^11]。然而，对于NV等其他显卡，这种做法的性能可能会更差[^12]。

#### AC: CPU

CPU端的工作：

- 粗糙的（instance级别的）quad tree culling。follow up[^9]里提到的做法是，把object的位置和bounding sphere radius压缩成64-bit，然后frustum culling。
- 更新GPU端所需的per-instance data，例如transform, LOD。这些不会涉及渲染状态的切换。
- 根据包围盒深度排序draw call
- 基于non-instanced data，例如material和renderstate，merge drawcall。merge的时候保持原本的顺序，所以merge之后每个batch仍然是排序过的。

#### AC: GPU

GPU端：

- 对于每个instance，根据instanceId拿到transform, bounds以及mesh，做instance级别的frustum + occlusion culling；
- 剩下的instance展开成cluster，根据clusterId拿到cluster bounds，做frustum + occlusionculling。另外，还会拿到pre-baked triangle visibility，做triangle backface culling；
- 剩下的triangle用来构建compacted index buffer，空的drawcall会被丢弃；
- 每个batch一发MultiDrawIndexInstancedIndirect

一个问题是MultiDraw里的每个sub-drawcall（对应一个instance）如何获取instanceId，去得到instance的数据。对于OpenGL，一种做法是在index compaction阶段同时构建一个buffer，把multiDraw里每个sub-drawcall的instanceId写进去，在shader里用`gl_DrawID`去取。对于Dx12，则可以用command signature直接把instanceId当做command的一个参数[^13]。

#### AC: Occlusion Details

- 基于bounds、artists的设置以及深度，选择300个occluder做depth prepass，随后downsample。
- reproject上一帧的深度图。为了避免明显的false occluder，靠近相机的occluder会被忽略。
- 合并两张深度图，生成Hi-Z。

### Nanite Occlusion Culling

Nanite同样会做cluster occlusion culling。

- 核心idea: 上一帧可见的物体，很可能在这一帧也可见。
- First pass: 绘制上一帧可见的所有物体，生成HZB
- Second pass: 对剩下的cluster，把bound投影到屏幕空间矩形，用HZB做occlusion culling。。

相比AC的一大优点是不用reproject上一帧的深度图，画的都是物体在这一帧的位置，所以是保守的culling。

## Visibility

### Background: Decoupled material

Idea: 输出一个全屏的visibility buffer，一般至少会包含triangleId和instanceId[^14]。HZB做culling的效率很高，所以一般也会输出depth。根据不同的变种，这个buffer也可以称为thin gbuffer, attribute buffer, etc.

有的方案也会输出barycentric。如果不存的话，需要在shading的时候再做一遍vertex position fetch + model transform，然后把screen ray投影到世界坐标中计算barycentric[^14]。

decoupled material的主要的优点是[^14][^15]：

- visibility buffer存的东西很少，并且只有可见的像素会有texture sampling，节省bandwidth；
- 几乎不存在material overdraw。即使是延迟渲染，也可能会对最终不可见的像素做material evaluation。如果想要完全避免这点就需要depth prepass，额外开销同样很大；
- 不需要根据material去batch drawcall，最开始提交drawcall的时候也不需要切pipeline了，真正的一发drawcall渲染所有(opaque) geometry.

主要的流程是[^16]：

- 输出visibility buffer
- 根据material的种类，分类pixel
- 每一种material分别处理。forward就直接渲染了，deferred用material shader输出到gbuffer。

**放[^14]的pipeline对比图**

#### DM: Dispatch

为了根据material分别做shading，我们需要知道每个material对应了哪些pixel。最简单的思路是开等同于material种类数量的buffer，每个记录哪些pixel用了对应的material。然而，这样bandwidth会很大。

在只能开一个buffer的情况下，我们想到的就是排序。由于material的数量已经提前确定，我们可以做counting sort。具体来说，遍历pixel记录每种material对应的数量，做一个前缀和算出每个material的offset，最后把pixel的屏幕空间坐标按照offset添加到一个buffer里。[^16]

**放[^16]的图**

一个小问题是，计算每个material对应的pixel数量时用的是global atomic，而在material数量不多的情况下会有很多contention。解决办法是先以tile做局部统计，再添加到global atomic里。

下一步是根据material去dispatch shader。最简单的思路是每个material一发dispatch indirect，但在material很多的情况下开销会很大。最后文章采取的办法是shader jump的hack + bindless。这篇[^15]提到了现代API的一种替代方法。

#### DM: Another Approach For Drawcall

The Dawn Engine[^17]提出了另外一种思路。在visibility buffer之后，他们引入了一个full-screen pass，把materialId写入了一个depth buffer，然后每种material做drawcall的时候，就可以在early depth test阶段用DEPTH_EQUAL的深度测试剔除所有不使用当前material的pixel。在这一步还可以加入clustered做light culling。drawcall的范围是所有使用当前material的mesh instance的screen space bounds。为了得到这个bounds，需要把instanceId按照material组合（比如counting sort），然后基于visibility数据，对于每种
material分配一个thread group去算bounding box。

## Cluster

### Scaling Insights

Nanite的目标是不管场景有多复杂都能work。也就是说，我们可以允许$$O(\#instance)$$的开销，但是决不能接受$$O(\#triangle)$$的。Ray tracing是$$log(n)$$的，然而cache miss是个大问题。

进一步的思考就是，我们不应该画比pixel数量更多的triangle；而实现这一点的方法就是LOD。

### Cluster Hierarchy

Cluster hierarchy最简单的想法是用树状结构组织cluster LOD，其中父节点是它所有子节点的简化版本。如果在当前视角下判断选用父节点和子节点看不出太大差别，就选择父节点。这样就可以像virtual texturing一样按需加载。

**放LOD Hierarchy的图**

#### Build Stage

一个问题是，如果相邻的两个cluster选取了不同级别的LOD，那么在边缘就容易出现crack（比如T-junction）。在生成LOD的时候lock edge看似是一种解决方案，但是当一条边在很多层level里都保持着lock的状态，就会在附近产生很多密集的小三角形，导致整体分布不均匀。这里的直觉是，某一个level的cluster boundary对应着树上那一个level相邻子节点的空隙。如果在树上，从某个节点向下画一条线穿过许多level，没有和树的edge相交，就意味着这条边界会被lock很久，也就会有问题。

**Cracks的图**

解决的思路是，构建LOD的过程中，在恰当的时候group cluters，让它们作为选择同一个LOD(如果group整个mesh就是退化到传统LOD)，并且在group之间lock edge。

为了不让同一edge在多个level之间都lock，LOD N的group boundary，在LOD N+1的时候处在group内，也就是不会继续被lock。具体的实现方法是：

- 现在我们处于k级LOD；把cluster拆成多个group，比如说某个group有N个cluster，对应N * M个三角形
- 把这个group里的三角形merge & simplify，得到原本数量一半的三角形 (N * M / 2)
- 把这个group拆成N/2个cluster，得到k+1级LOD
- 重复，直到只剩下一个cluster。

**放五颜六色的cluster boundary的图**

这张图里的boundary是cluster group的boundary，而不是cluster的。

#### Runtime stage

LOD selection的是保证一个group里的所有cluster都选取相同的LOD。这句话困扰我的地方在于（借用一下GAMES104的图[^18]）：

**GAMES104的图**

这张图里中间那层LOD里，一个黑框是一个group，但是如果去做一个cut:

**手绘GAMES104 LOD Cut，跨过三层的合法cut**

看起来一个黑框里的cluster并不一定都要选。

所以这里的group到底指什么？之前提到，选取group的目的是为了让group内的boundary不被lock。也就是说，我们理应可以沿着任意被lock的boundary去切这张DAG。而被lock的boundary，在DAG上就表现为一个level之间的空隙。此外，我们还希望对于每一个叶子结点，至少有一个祖先节点会被选取，而这一限制在图上的体现就是cut不能和edge相交。所以直觉上来说，一个合法的cut一定对应着一种合法的selection。不过一种合法的selection似乎不一定能表示成一个cut，比如uiuc给的这个图[^19]。（不过这并不影响，因为实际上我们不会真的做DAG traversal，所以这种selection是会出现的）

**放uiuc的图，加上手绘的看似非法实则合理的cut**

所以可能不应该从cut的角度去理解，而是沿用之前树状图的直觉。tree是自底向上、多个变成一个的LOD抽象，现在的DAG只不过是N变M的 ($$M\lt N$$)。也就是说，我们还是从所有的leaf开始，选一部分leaf node（一个group）替换成更上一层的，如此反复。这也就是Nanite说的，一个group有可以互换的两种表示。

在运行时遍历巨大的DAG来做selection是不可接受的，所以我们需要找到一个局部的、因而可以并行的方法。具体的做法是，在build的时候让父节点的error不小于子节点的，这样一个threshold可以确定最多一个合理的cut。并且，只要threshold足够小，使得error是subpixel级别的，那么父子节点之间的切换过程就会被TAA掩盖掉。

有了局部的判断条件，我们就可以根据DAG建立一个BVH，使得每个node的children都是它在DAG里的descendants。由于LOD0的cluster group是不可能只被部分选中的，最底层的cluster就以group为单位作为leaf node。具体的LOD culling做法是用固定数量的线程+任务队列：每个线程拿出一个node，做culling，通过了就把children加入。

[^1]: [2021 Nanite: A Deep Dive](https://advances.realtimerendering.com/s2021/Karis_Nanite_SIGGRAPH_Advances_2021_final.pdf)

[^2]: [2008 John Carmack on idTech6, Ray Tracing, Consoles, Physics and More](https://pcper.com/2008/03/john-carmack-on-id-tech-6-ray-tracing-consoles-physics-and-more/)

[^3]: [2010 Efficient Sparse Voxel Octrees](https://research.nvidia.com/sites/default/files/pubs/2010-02_Efficient-Sparse-Voxel/laine2010i3d_paper.pdf)

[^4]: [2015 GPU-Driven Rendering Pipelines](https://advances.realtimerendering.com/s2015/aaltonenhaar_siggraph2015_combined_final_footer_220dpi.pdf)

[^5]: [2013 Introducing the Programmable Vertex Pulling Rendering Pipeline, GPU Pro 4]

[^6]: [VkGuide: GPU Driven Rendering](https://vkguide.dev/docs/gpudriven)

[^7]: [游戏引擎随笔：现代图形API的Bindless](https://zhuanlan.zhihu.com/p/136449475)

[^8]: [2012 Graphics Gems for Games - Findings from Avalanche Studios](https://www.humus.name/Articles/Persson_GraphicsGemsForGames.pdf)

[^9]: [2015 GPU-Driven Rendering Followup](https://forum.beyond3d.com/threads/gpu-driven-rendering-siggraph-2015-follow-up.57240/)

[^10]: [Programmable vertex fetching and index buffering](https://forum.beyond3d.com/threads/programmable-vertex-fetching-and-index-buffering.57591/)

[^11]: [2018 Vertex Formats Part 2: Fetch vs Pull](https://www.yosoygames.com.ar/wp/2018/03/vertex-formats-part-2-fetch-vs-pull/)

[^12]: [2017 WICKED ENGINE: Should we get rid of Vertex Buffers?](https://wickedengine.net/2017/06/should-we-get-rid-of-vertex-buffers/)

[^13]: [2016 Optimizing the Graphics Pipeline with Compute](https://ubm-twvideo01.s3.amazonaws.com/o1/vault/gdc2016/Presentations/Wihlidal_Graham_OptimizingTheGraphics.pdf)

[^14]: [2013 The Visibility Buffer: A Cache-Friendly Approach to Deferred Shading](https://jcgt.org/published/0002/02/04/)

[^15]: [2016 Modern textureless deferred rendering techniques](https://forum.beyond3d.com/threads/modern-textureless-deferred-rendering-techniques.57611/)

[^16]: [2015 A Deferred Material Rendering System](https://onedrive.live.com/view.aspx?resid=EBE7DEDA70D06DA0!115&app=PowerPoint&authkey=!AP-pDh4IMUug6vs)

[^17]: [2017 "Deferred+: Next-Gen Culling and Rendering for Dawn Engine"](http://gpuzen.blogspot.com/)

[^18]: [GAMES104](https://games104.boomingtech.com/)

[^19]: [UIUC CS418 Nanite](https://cs418.cs.illinois.edu/website/text/nanite.html)